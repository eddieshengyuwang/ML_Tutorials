{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Linear Regression Tutorial\n",
    "<br>\n",
    "In the previous tutorial, we predicted restaurant profits (our **label**) using linear regression based on a sole **feature**, which was the population of cities that restaurants were located in. However at often times, there are more than one features that affect the label, for example size of the restaurant in square feet, number of competitors within its vicinity, etc. In this situation, we use **Mutivariate Linear Regression** which occurs when we want to perform linear regression when our data set has more than one feature. \n",
    "\n",
    "Note that since the dataset is multivariate, we are dealing with **multi-dimensional** data, which cannot be represented on a 2D graph. The best we can do for visualization is to use a 3D graph, but that is only in the special case that there are two features and one label (ie. predicting restaurant profits based on only two factors, like population of city and size of restaurant). However in practice, often times there are more than two features that determine a label, which makes it difficult to depict our data in a graph.\n",
    "\n",
    "For this tutorial, we will use the dataset \"ex1data2.txt\" found in this directory to predict housing prices. The dataset comes with three columns: Size of house (in square feet), number of bedrooms, and price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Size of house (sq ft)  Number of bedrooms  Price of house\n",
      "0                   2104                   3          399900\n",
      "1                   1600                   3          329900\n",
      "2                   2400                   3          369000\n",
      "3                   1416                   2          232000\n",
      "4                   3000                   4          539900\n",
      "\n",
      "\n",
      "    Size of house (sq ft)  Number of bedrooms  Price of house\n",
      "42                   2567                   4          314000\n",
      "43                   1200                   3          299000\n",
      "44                    852                   2          179900\n",
      "45                   1852                   4          299900\n",
      "46                   1203                   3          239500\n"
     ]
    }
   ],
   "source": [
    "# Once again, the first step is to import libraries and load our DataFrame. \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# although our data is 3D, we are not going visualize our dataset/prediction\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('ex1data2.txt', names = ['Size of house (sq ft)',\n",
    "                                          'Number of bedrooms',\n",
    "                                          'Price of house'])\n",
    "print(df.head(5))\n",
    "print('\\n')\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With multivariate linear regression, we need to introduce some new notation:\n",
    "- m is the number of data points (46 in this example)\n",
    "- n is the number of features (2 in this example)\n",
    "- $x^{(i)}_j$ is the value at the j-th feature on the i-th training example ($x^{(43)}_1$ = 1200, 1st feature on 43rd data point)\n",
    "- $y^{(i)}$ is the i-th label ($y^{(4)}$ = 539900)\n",
    "\n",
    "<br>\n",
    "Recall the equation of a line for SLRM:\n",
    "$$ y = \\theta_0x_0 + \\theta_1x_1 = \\theta_0 + \\theta_1x_1 $$\n",
    "\n",
    "For multivariate linear regression, our new equation (which we will call the hypothesis function) is: \n",
    "<br>\n",
    "<br>\n",
    "\\begin{align*}\n",
    "h(x) & = \\theta_0x_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3 + ... + \\theta_nx_n &&& \\text{note: }x_0 = 1 \\\\\\\\\n",
    "    & = \\left [  \\theta_0~\\theta_1~...~\\theta_n\\right ]\\begin{bmatrix}\n",
    "x_0\\\\ \n",
    "x_1\\\\ \n",
    "...\\\\\n",
    "x_n \n",
    "\\end{bmatrix} \\\\\n",
    " & = \\theta^Tx\n",
    "\\end{align*}\n",
    "<br>\n",
    "<br>\n",
    "Similarly, recall the gradient descent algorithm for SLRM that for each iteration we set:\n",
    "$$ \\theta_0 = \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta_0 + \\theta_1x^{(i)} - y^{(i)}) \\\\ \\theta_1 = \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta_0 + \\theta_1x^{(i)} - y^{(i)})~ x^{(i)} $$\n",
    "\n",
    "However for multiple variables, for each iteration in the gradient descent algorithm, we set:\n",
    "\\begin{align*}\n",
    "\\theta_0 &= \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta_0 + \\theta_1x^{(i)}_1 + \\theta_2x^{(i)}_2 + ... + \\theta_nx^{(i)}_n - y^{(i)}) \\\\\n",
    "        &= \\theta_0 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m} (\\theta^Tx^{(i)} - y^{(i)}) \\\\\n",
    "\\theta_1 &= \\theta_1 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta^Tx^{(i)} - y^{(i)})~ x^{(i)}_1 \\\\\n",
    "\\theta_2 &= \\theta_2 - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta^Tx^{(i)} - y^{(i)})~ x^{(i)}_2 \\\\ \n",
    "& =~... \\\\\n",
    "\\theta_n &= \\theta_n - \\alpha\\frac{1}{m}\\sum_{i=1}^{m}(\\theta^Tx^{(i)} - y^{(i)})~ x^{(i)}_n \\\\\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
