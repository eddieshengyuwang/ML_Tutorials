# Coursera ML Assignment Tutorials

Here you can find implementation and explanations of all the assignments in Andrew Ng's Machine Learning course on Coursera written in Python instead of Octave.

[ex1 (pt. 1) - Simple Linear Regression]( 
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex1_LinearRegression/gr_desc_SLRM.ipynb) <br/>
(Topics Covered:)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Linear regression cost function <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Gradient descent <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Vectorization<br/>

[ex1 (pt. 2) - Multivariable Linear Regression](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex1_MultiRegre/Multivariate%20Linear%20Regression.ipynb)  <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Feature scaling/normalization <br/>

[ex2 (pt. 1) - Logistic Regression](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex2_LogRgr/Log_Regr_Tut.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Decision boundary <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Sigmoid function <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Logistic regression cost function <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Scipy Optimization <br/>

[ex2 (pt. 2) - Logistic Regression with Regularization](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex2_LogRgr/Log_Regr_Tut2.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Polynomial features <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Regularization <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Underfitting/overfitting <br/>


[ex3 - Multiclass Logistic Regression and Intro to Neural Networks](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex3_MultiLog/MultiLogTut.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- One vs all <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Feed forward neural network <br/>


[ex4 - Neural Networks In Depth](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex4_NN/NN_2.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- One hot encoding <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Backpropogation <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Neural network cost function <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Sigmoid gradient <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Parameter unrolling <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Gradient checking <br/>

[ex5 - Regularized Linear Regression and Bias vs. Variance](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex5_biasVar/BiasVar.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Bias vs variance <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Learning curves <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Hyperparameter tuning <br/>

[ex6 (pt. 1) - Support Vector Machines](
https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex6_SVM/SVMs.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Linear SVM <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Gaussian kernel SVM <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Hyperparameter tuning <br/>

[ex6 (pt. 2) - Spam Classification using SVMs](https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex6_SVM/Spam.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Text transformations <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Stemming <br/>

[ex7 - K-Means Clustering and PCA](https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex7_KmeansPCA/Kmeans_PCA.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- K-means clustering algorithm <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Image compression with k-means <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Projections, singular value decomposition <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Image compression with PCA<br/>

[ex8 (pt. 1) - Anomaly Detection](https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex8_AnomalyRec/Anon.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Maximum likelihood estimates<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Multivariate normal distribution <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- F1 score <br/>


[ex8 (pt. 2) - Recommendation Engines](https://nbviewer.jupyter.org/github/eddieshengyuwang/ML_Tutorials/blob/master/ex8_AnomalyRec/Rec.ipynb)<br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Collaborative filtering cost function and gradient <br/>
&nbsp;&nbsp;&nbsp;&nbsp;- Gradient checking <br/>


